---
title: "ISYE 6402 Homework Spring 2024"
output: html_document
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Part 1: EXT FUNDS Gold Price Exchange Analysis

# Background

In this problem, we will study fluctuations in The NEXT FUNDS Gold Price Exchange Traded Fund that is a type of investment fund that aims to track the performance of gold prices. By investing in this fund, investors can gain exposure to the price movements of gold without having to physically own the metal. The fund holds physical gold as its underlying asset, and its value is based on the market price of gold.
You will use the file Fund Prices Data.csv, where monthly prices are from January 2010 to Dec 2022.


## Instructions on reading the data

To read the data in R, save the file in your working directory (make sure you have changed the directory if different from the R working directory) and read the data using the R function read.csv()

You will perform the analysis and modelling on the Close data column.

```{r, warning=FALSE, message=FALSE}

#Here are the libraries you will need:

library(mgcv)
library(TSA)
library(dynlm)
library(ggplot2)
library(reshape2)
library(greybox)
library(mlr)
library(mgcv)
library(lubridate)
library(dplyr)
library(data.table)
library(forecast)

```

```{r}
#Run the following code to prepare the data for analysis:

data<-read.csv("Fund Prices Data.csv")

```

## Question 1a: Exploratory Data Analysis 

Plot the Time Series and the ACF plot for the series. Comment on the stationarity of both time series based on these plots. Which (if any) stationarity assumptions are violated for the time series?

```{r}
# use View() and str() to check date type and it was char, then use mdy() from lubridate package convert char date to Date type, then re-check data by View() and str()

data$Date = mdy(data$Date)
#View(data)
#str(data)

```


```{r}
# Use ts() and acf() to plot time series data.
time.data = as.vector(t(data[,-1]))
time.data = ts(time.data, start=2010, frequency = 12)
ts.plot(time.data)

acf.data = acf(time.data)
acf.data

```

**Response: 1a**
from both plots, there are signs of trend.  and correlation is very strong at beginning, as we increase the lags, the correlation decreases. so it is a violation of stationarity since the mean is not constant.


## Question 1b: Trend Estimation

Fit the following trend estimation models:

- Moving average
- Parametric quadratic polynomial
- Local Polynomial
- Splines

Overlay the fitted values derived from each trend estimation model on the corresponding data. Comment on the effectiveness of each model to estimate the trend for the series.

```{r}
# references: lectures
ma.pts = c(1:length(time.data))
ma.pts = c(ma.pts - min(ma.pts))/max(ma.pts)

# moving average
mav.fit = ksmooth(ma.pts, time.data, kernel = "box")
time.data.fit.mav = ts(mav.fit$y,start=2010,frequency=12)
ts.plot(time.data,ylab="Close")
lines(time.data.fit.mav,lwd=2,col="purple")

#  Parametric quadratic polynomial
x1 = ma.pts
x2 = ma.pts^2
lm.fit = lm(data$Close~x1+x2)
summary(lm.fit)
t.fit.lm = ts(fitted(lm.fit),start=2010,frequency=12)
ts.plot(time.data,ylab="Close")
lines(t.fit.lm,lwd=2,col="green")

# Local Polynomial
loc.fit = loess(time.data~ma.pts)
t.fit.loc = ts(fitted(loc.fit),start=2010,frequency=12)
ts.plot(time.data,ylab="Close")
lines(t.fit.loc,lwd=2,col="blue")

## Splines Trend Estimation
gam.fit = gam(time.data~s(ma.pts))
t.fit.gam = ts(fitted(gam.fit),start=2010,frequency=12)
ts.plot(time.data,ylab="Close")
lines(t.fit.gam,lwd=2,col="red")

#overlay all 
all = c(time.data.fit.mav, t.fit.lm, t.fit.gam, t.fit.loc)
ylim= c(min(all),max(all))
time.data = ts(time.data, start=2010, frequency = 12)
ts.plot(time.data)
lines(t.fit.lm,lwd=2,col="green",ylim=ylim)
lines(time.data.fit.mav,lwd=2,col="purple")
lines(t.fit.gam,lwd=2,col="red")
lines(t.fit.loc,lwd=2,col="brown")
legend(x=1900,y=64,legend=c("MAV","LM","GAM","LOESS"),lty = 1, col=c("purple","green","red","brown"))

```

**Response: 1b**
Splines Trend Estimation is the most proper trend estimation line. 



## Question 1c: Residual Analysis

Evaluate the quality of each fit using the residual analysis.

```{r}
# reference: lecture notes
# remove trend and seasonality
Close.tr = sqrt(data$Close+3/8)
resid = Close.tr - fitted(gam.fit)
acf(resid,lag.max=12*4,main="",col="brown")

# ma
diff.moving = ts(time.data - time.data.fit.mav, start = 2010, frequency = 12)
ts.plot(diff.moving, ylab= "moving average residual process")
acf(diff.moving)

# paramatic 
diff.para = tsdiff.moving = ts(time.data - t.fit.lm, start = 2010, frequency = 12)
ts.plot(diff.para, ylab= "paramatric Polynomial residual process")
acf(diff.para)

#Local
diff.loc = ts(time.data - t.fit.loc, start = 2010, frequency = 12)
ts.plot(diff.loc, ylab= "local Polynomial residual process")
acf(diff.loc)

#spline
diff.spline = ts(time.data - t.fit.gam, start = 2010, frequency = 12)
ts.plot(diff.loc, ylab= "spline Polynomial residual process")
acf(diff.spline)

```
**Response:1c**
moving trend and seasonality: autocorrelation in the plot at different lags is decreasing, indicating that the residuals are not behaving like white noise and that the model may need adjustments. The ACF of residuals shows a quick decreasing towards zero, indicating no significant autocorrelation at any lag, signifying a well-fitted model. 

Moving average: the residual plot does not show spikes, indicating a finite variance. ACF plot does not decay to zero indicating no violation of the constant mean. So it is non-stationary.

Paramatric: the residual plot does not show spikes, indicating a finite variance. ACF plot does not decay to zero indicating no violation of the constant mean. So it is non-stationary.

Local polynomial: the residual plot does not show spikes, indicating a finite variance.but ACF plot shows a trend of decay to zero and then back to zero, which means the residuals still have some seasonality, which means it is non-stationary. 

Splines: the residual plot does not show spikes, indicating a finite variance. The ACF plot does not decay to zero and have a pattern indicating a seasonality, implying non-stationary.

## Question 1d: Differenced Data Modeling

Now plot the difference time series and its ACF plot. Apply the four trend models in Question 1b to the differenced time series. What can you conclude about the difference data in terms of stationarity? Which model would you recommend to apply (trend removal via fitting trend vs differencing) such that to obtain a stationary process?

```{r}
# reference:https://www.google.com/search?q=plot+the+difference+time+series+and+its+ACF+plot+in+r&oq=plot+the+difference+time+series+and+its+ACF+plot+in+r&gs_lcrp=EgZjaHJvbWUyBggAEEUYOTIHCAEQIRigATIHCAIQIRigATIHCAMQIRigATIHCAQQIRigATIHCAUQIRiPAjIHCAYQIRiPAjIHCAcQIRiPAtIBCDQ0NTNqMGo3qAIIsAIB&sourceid=chrome&ie=UTF-8#cobssid=s
# reference: https://www.cliffsnotes.com/study-notes/6737128


diff.data.ma = diff(time.data, 1)

plot(diff.data.ma)
acf(diff.data.ma)

diff.pts = c(1:length(diff.data.ma))
diff.pts = c(diff.pts - min(diff.pts))/max(diff.pts)

# moving average
diff.fit = ksmooth(diff.pts, diff.data.ma, kernel = "box")
diff.data.fit.mav = ts(diff.fit$y,start=2010,frequency=12)

#  Parametric quadratic polynomial
diff.x1 = diff.pts
diff.x2 = diff.pts^2
diff.lm.fit = lm(diff.data.ma~diff.x1+diff.x2)
summary(diff.lm.fit)
diff.fit.lm = ts(fitted(diff.lm.fit),start=2010,frequency=12)

# local polynomial
diff.local=loess(diff.data.ma~diff.pts) 
diff.local.fit =ts(fitted(diff.local),start =2010,frequency =12) 

#splines
diff.spline=gam(diff.data.ma~s(diff.pts)) 
diff.spline.fit=ts(fitted(diff.spline),start =2010,frequency =12)

# plot all
ts.plot(diff.data.ma,ylab ="close") 
lines(diff.data.fit.mav,lwd =2,col ="red") 
lines(diff.fit.lm,lwd =2,col ="orange") 
lines(diff.local.fit,lwd =2,col ="yellow") 
lines(diff.spline.fit,lwd =2,col ="green")

```

**Response 1d**

The trends generated by the four models are almost same which means there are no trend in the differenced data, implies differenced data is a stationary data.




# Part 2: Temperature Analysis

# Background

In this problem, we will analyze quarterly average temperature data. The data file Temperature HW 2.csv contains average monthly temperature from a southern region from January 1980 through Dec 2016. We will aggregate the data on a quarterly basis, by taking the average rate within each quarter.  We will fit the models on the data until Quarter 4 of 2015 and evaluate the predictions for Q1 to Q4 2016. 

## Instructions on reading the data

To read the data in R, save the file in your working directory (make sure you have changed the directory if different from the R working directory) and read the data using the R function read.csv()

You will perform the analysis and modelling on the Temperature data column.

```{r}

#Run the following code to prepare the data for analysis:

df2 <- read.csv("Temperature HW 2.csv", head = TRUE)
temp <- ts(df2$Temperature, freq = 12, start = c(1980,1))
temp <- aggregate.ts(temp, nfrequency = 4)
```

## Question 2a: Exploratory Data Analysis 

Plot both the Time Series and ACF plots. Comment on the main features, and identify what (if any) assumptions of stationarity are violated. Additionally, consider the differenced data and comment on its features. Support your response with a graphical analysis.


```{r}
# plots of time series data and its acf. 
# reference:https://www.cliffsnotes.com/study-notes/6737128, https://www.rdocumentation.org/packages/base/versions/3.6.2/topics/diff, https://www.google.com/search?q=why+seasonality+violates+stationarity+in+time+series+data&oq=why+seasonality+violates+stationarity+in+time+series+data&gs_lcrp=EgZjaHJvbWUyCQgAEEUYORigATIHCAEQIRigATIHCAIQIRigATIHCAMQIRigATIHCAQQIRifBTIHCAUQIRifBTIHCAYQIRifBTIHCAcQIRifBTIHCAgQIRifBTIHCAkQIRifBdIBCTMyMDkwajBqN6gCALACAA&sourceid=chrome&ie=UTF-8
# all codes below uses the references provided above. 

ts.plot(temp)
acf(temp, lag.max = 100, type = "correlation")
```

```{r}
# differencing data
diff.temp = diff(temp)
ts.plot(diff.temp)
acf(diff.temp, lag.max = 100)
```

**Response: 2a**
Both plots of time series data and differencing data showed seasonality, it indicates non-stationary. Because the seasonality shows a repeating pattern over time intervals, which causes mean or variance to change periodically.



## Question 2b: Seasonality Estimation

Separately fit a seasonality harmonic model and the ANOVA seasonality model to the temperature data. Evaluate the quality of each fit using the residual analysis. Does one model perform better than the other? Which model would you select to fit the seasonality in the data?

```{r}
# lecture notes and first references from above

# seasonality harmonic model
har.model = lm(temp~harmonic(temp))
har.fit = ts(fitted(har.model), start =  1980, frequency = 4)

diff.har = ts(temp - har.fit, start = 1980, frequency = 4)
ts.plot(diff.har, ylab="harmonic model residual analysis")
acf(diff.har, lag.max = 100)

# anova model
ano.model = lm(temp ~ season(temp))
ano.fit = ts(fitted(ano.model), start = 1980, frequency = 4)

diff.ano = ts(temp - ano.fit, start = 1980, frequency = 4)
ts.plot(diff.ano, ylab="anova model residual analysis")
acf(diff.ano, lag.max = 100)

```

**Response: 2b**
from the acf plots of two models, the first model, harmonic model still shows a seasonality, whereas the anova model doesnt show a seasonal pattern. so i think anova model fitts better to the residual data, I would choose anova model. 



## Question 2c: Trend-Seasonality Estimation

Using the time-series data, fit the following models to estimate the trend with seasonality fitted using ANOVA:

 - Parametric quadratic polynomial
 - Non-parametric model
 
Overlay the fitted values of the two models on the original time series. What do you conclude in terms of trend over time?

Plot the residuals with respect to time. Plot the ACF of the residuals. Comment on how the two models fit and on the appropriateness of the stationarity assumption of the residuals.

What form of modeling seems most appropriate and what implications might this have for how one might expect long term temperature data to behave? Provide explicit conclusions based on the data analysis.

```{r}
# lecture notes
time.pts = c(1:length(temp))
time.pts = c(time.pts - min(time.pts)/max(time.pts))

# paramatric 
x1=time.pts
x2=time.pts^2

para= dynlm(temp~x1+x2+season(temp))
para.fit = ts(fitted(para), start = 1980, frequency = 4)

# non paramatric
spline = gam(temp~s(time.pts) + season(temp))
spline.fit= ts(fitted(spline), start = 1980, frequency = 4)

# overlay two models with original data
ts.plot(temp)
lines(para.fit, col="red")
lines(spline.fit, col="blue")

# residual analysis with two models
# residual analysis on parametric 
para.diff = ts(temp - para.fit, start = 1980, frequency = 4)
ts.plot(para.diff)
acf(para.diff, lag.max = 100)


# residual analysis on non paramatric
spline.diff = ts(temp-spline.fit, start =1980, frequency = 4)
ts.plot(spline.diff)
acf(spline.diff, lag.max = 100)

```
**Response:2c**
(1) overlay plot shows a trend with no increasing or decreasing tendency. 
(2) both models captured trough in residual plots
(3) from acf of both residual plots. could not find a clear pattern. 
(4) maybe parametric polynomial model performs a little better since its acf value looks a little smaller compare with spline model.
(5) from long term view, we should expect a steady trend and seasonality.



## Question 2d: Prediction

Using the trend-seasonality models, predict the temperature data for 4 quarters ahead (Q1 to Q4 2016). Apply both one step ahead rolling predictions as well as predictions 4 steps ahead.  Note that we have had an unusual heated summer this year. How do your predictions compare with the observed average temperature?

Hints: 

- Keep in mind that modeling factors may require extra steps on the data preparation. 

- To predict, you may want to rename the columns of your training data, you could use: setnames(your_data, old = c(), new = c()).

-  You can use predict, or predict.gam for your predictions. 

```{r}



```

**Response: 2d**
