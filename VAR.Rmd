---
title: "Proj-Var"
output: html_document
date: "2025-04-23"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


```{r cars}
library(data.table)
library(vars)
library(xts)
library(mgcv)
library(stats)
library(tseries)
library(aod)
library(zoo)
library(lubridate)
library(fGarch)
library(ggpubr)
library(ggfortify)
library(quantmod)
library(urca)
library(forecast)
library(mFilter)
library(TSstudio)
library(tidyverse)
library(bruceR)
library(rugarch)
```


```{r pressure, echo=FALSE}
##### this chunk of the code below is used to identify and remove extreme points
# here i checked extreme points in the original data without convert them to time series. 
data2 = read.csv("VehicleData-1.csv", header = T)
data2$DATE = as.Date(data2$DATE, format =  "%m/%d/%Y")
data2 %>% mutate_all(~replace(., is.nan(.), 0))
```

```{r}
## identify extreme points in the total sales.
max.sales = data2[which.max(data2$Total.Sales), ]
max.sales

min.sales = data2[which.min(data2$Total.Sales), ]
min.sales
```


```{r}
## identify extreme points in the new orders
max.orders = data2[which.max(data2$New.Orders), ]
max.orders

min.orders = data2[which.min(data2$New.Orders), ]
min.orders
```


```{r}
## remove those identified extreme points from total sales and new orders

## remove one max and two min values of tatal sales from dataframe, which is (date) 0001-10-01 and 2020-04-01
data2 = data2[data2$Total.Sales < 22.055,	]
data2 = data2[data2$Total.Sales > 11.736, ]

## first to remove two min values of new orders from dataframe, which is (date) 2020-04-01 since it was during Covid. 
data2 = data2[data2$New.Orders < 64455, ]
data2 = data2[data2$New.Orders > 24561	,	]

head(data2)

# nrow() to find number of points, length to find how many columns.
nrow(data2)

```

The code above is to remove three months from 2020, which are March, Apirl and May, those values are either extreme point or very close to be an extreme points. But in general, I feel the values of sales and orders were generally very low in the year 2020, which still caused a trough even I removed three "extreme" points.which can be seen from the plot below. 


```{r}
## now convert the data with extreme values removed 
new.sales = ts(data2$Total.Sales, start = c(2000,1,1), frequency = 12)
new.orders = ts(data2$New.Orders, start = c(2000,1,1), frequency = 12)
```


```{r}
new.sales.plot = autoplot(new.sales) + xlab("date") + ylab("sales") + ggtitle("Total Sales") 
new.sales.plot

new.orders.plot = autoplot(new.orders) + xlab("data") + ylab("orders") + ggtitle("New Orders")
new.orders.plot
```


```{r}
### since the value of Total sales is seasonally adjusted annual rate, I need to translate the value of new orders to seasonally adjusted annual rate too just to match the total sales with same units.

year = format(data2$DATE, "%y")
new.mean = aggregate(New.Orders~year, data2, mean)
#new.mean[,1]
#new.mean[,2]
newdata = data.frame(year = new.mean[,1], year_mean = new.mean[,2])
newdata

library(dplyr)
newdata = newdata%>%mutate(month.mean = year_mean/12)
newdata
data2 = data2%>%separate(DATE, c("year", "month", "day"), sep = "-")

split.year = split(data2, data2$year)

data2
```

```{r}
zero = data.frame(data2[data2$year == 0, ])
zero$rate = 0
for (a in 1:length(zero$New.Orders)){
  zero$rate[a] = zero$New.Orders[a]/ 3242.389 
}

one = data.frame(data2[data2$year == 1, ])
one$rate = 0
for (a in 1:length(one$New.Orders)){
  one$rate[a] = one$New.Orders[a]/ 2962.939	
}

two = data.frame(data2[data2$year == 2, ])
two$rate = 0
for (a in 1:length(two$New.Orders)){
  two$rate[a] = two$New.Orders[a]/ 3267.312		
}

three = data.frame(data2[data2$year == 3, ])
three$rate = 0
for (a in 1:length(three$New.Orders)){
  three$rate[a] = three$New.Orders[a]/ 3428.694		
}

four = data.frame(data2[data2$year == 4, ])
four$rate = 0
for (a in 1:length(four$New.Orders)){
  four$rate[a] = four$New.Orders[a]/ 3415.549			
}

five = data.frame(data2[data2$year == 5, ])
five$rate = 0
for (a in 1:length(five$New.Orders)){
  five$rate[a] = five$New.Orders[a]/ 3492.632				
}

six = data.frame(data2[data2$year == 6, ])
six$rate = 0
for (a in 1:length(six$New.Orders)){
  six$rate[a] = six$New.Orders[a]/ 3481.326				
}

seven = data.frame(data2[data2$year == 7, ])
seven$rate = 0
for (a in 1:length(seven$New.Orders)){
  seven$rate[a] = seven$New.Orders[a]/ 3461.674					
}

eight = data.frame(data2[data2$year == 8, ])
eight$rate = 0
for (a in 1:length(eight$New.Orders)){
  eight$rate[a] = eight$New.Orders[a]/ 2996.361					
}

nigh = data.frame(data2[data2$year == 9, ])
nigh$rate = 0
for (a in 1:length(nigh$New.Orders)){
  nigh$rate[a] = nigh$New.Orders[a]/ 2122.000					
}

ten = data.frame(data2[data2$year == 10, ])
ten$rate = 0
for (a in 1:length(ten$New.Orders)){
  ten$rate[a] = ten$New.Orders[a]/ 2890.646						
}

ele = data.frame(data2[data2$year == 11, ])
ele$rate = 0
for (a in 1:length(ele$New.Orders)){
  ele$rate[a] = ele$New.Orders[a]/ 3116.896						
} 

twe = data.frame(data2[data2$year == 12, ])
twe$rate = 0
for (a in 1:length(twe$New.Orders)){
  twe$rate[a] = twe$New.Orders[a]/ 3542.403					
} 

thirteen = data.frame(data2[data2$year == 13, ])
thirteen$rate = 0
for (a in 1:length(thirteen$New.Orders)){
  thirteen$rate[a] = thirteen$New.Orders[a]/ 3791.562					
} 

fourteen = data.frame(data2[data2$year == 14, ])
fourteen$rate = 0
for (a in 1:length(fourteen$New.Orders)){
  fourteen$rate[a] = fourteen$New.Orders[a]/ 4179.000					
} 

fif = data.frame(data2[data2$year == 15, ])
fif$rate = 0
for (a in 1:length(fif$New.Orders)){
  fif$rate[a] = fif$New.Orders[a]/ 4457.993					
} 

sixth = data.frame(data2[data2$year == 16, ])
sixth$rate = 0
for (a in 1:length(sixth$New.Orders)){
  sixth$rate[a] = sixth$New.Orders[a]/ 4449.278						
} 

sev = data.frame(data2[data2$year == 17, ])
sev$rate = 0
for (a in 1:length(sev$New.Orders)){
  sev$rate[a] = sev$New.Orders[a]/ 4418.833						
} 

ei = data.frame(data2[data2$year == 18, ])
ei$rate = 0
for (a in 1:length(ei$New.Orders)){
  ei$rate[a] = ei$New.Orders[a]/ 4641.597						
} 

ni = data.frame(data2[data2$year == 19, ])
ni$rate = 0
for (a in 1:length(ni$New.Orders)){
  ni$rate[a] = ni$New.Orders[a]/ 4545.285							
} 

tw = data.frame(data2[data2$year == 20, ])
tw$rate = 0
for (a in 1:length(tw$New.Orders)){
  tw$rate[a] = tw$New.Orders[a]/ 4507.417							
} 

twone = data.frame(data2[data2$year == 21, ])
twone$rate = 0
for (a in 1:length(twone$New.Orders)){
  twone$rate[a] = twone$New.Orders[a]/ 4389.403							
} 

twtw = data.frame(data2[data2$year == 22, ])
twtw$rate = 0
for (a in 1:length(twtw$New.Orders)){
  twtw$rate[a] = twtw$New.Orders[a]/ 4914.208								
} 

twth = data.frame(data2[data2$year == 23, ])
twth$rate = 0
for (a in 1:length(twth$New.Orders)){
  twth$rate[a] = twth$New.Orders[a]/ 5134.861								
} 

twfour = data.frame(data2[data2$year == 24, ])
twfour$rate = 0
for (a in 1:length(twfour$New.Orders)){
  twfour$rate[a] = twfour$New.Orders[a]/ 5238.583								
} 
```


```{r}
newbind = rbind(zero,one, three,four,five,six,seven,eight,nigh, ten, ele, thirteen, fourteen, fif, sixth,sev, ei, ni, tw, twone, twtw, twth,twfour)

#newbind = newbind%>%mutate(Date.new = make_date(year, month, day))

newbind = newbind%>%mutate(date = ymd(paste(year, month, day)))

newbind$date = as.Date(newbind$date, format =  "%m/%d/%Y")
```


```{r}
newbind = data.frame(newbind)

newdata = data.frame(subset(newbind, select = c(date, Total.Sales, rate)))

colnames(newdata) = c("Date", "SAAR.Total.Sales", "SAAR.New.Orders")

head(newdata)

# check number of data points of dataframe, use nrow(), check number of row of one variable using length()
nrow(newdata)
length(newdata$SAAR.Total.Sales)
length(newdata$SAAR.New.Orders)

new.sales.rate = ts(newdata$SAAR.Total.Sales, start = c(2000,1,1), frequency = 12)
new.orders.rate = ts(newdata$SAAR.New.Orders, start = c(2000,1,1), frequency = 12)

new.sales.rate.plot = autoplot(new.sales.rate) + xlab("Date") + ylab("Total Sales") + ggtitle("Total Sales - Seasonally Adjusted Annual Rate") 
new.sales.rate.plot

new.orders.rate.plot = autoplot(new.orders.rate) + xlab("Date") + ylab("New Orders") + ggtitle("New Orders - Seasonally Adjusted Annual Rate")
new.orders.rate.plot

ts_data = ts(newdata[,-1],start=2000,frequency=12)
autoplot(ts_data,main='SAAR of Total Sales  &  SAAR of New Orders',ylab="SAAR",xlab= 'Date')
```


```{r}
diff_ts = diff(ts_data)
head(diff_ts)
autoplot(diff_ts, main="1st-order Differenced SAAR of Total Sales and New Orders", ylab="1st-order Differenced SAAR", xlab="Date")
```

```{r}
ggAcf(diff_ts[, "SAAR.Total.Sales"], lag.max=200, col="brown1", main="Differenced SAAR of Total Sales")
```


```{r}
ggAcf(diff_ts[, "SAAR.New.Orders"], lag.max=200, col="darkturquoise", main="differenced SAAR of New Orders")
```

(1) From ACFs, I think it is now white noise since most lags are within 95% confidence band, some of the lags are outside the confidence band, due to the rest 5%.
(2) Code below I will start using 1st differenced data, since I think it is a white noise after differencing



### VAR model
```{r}
colnames(diff_ts) = c( "New orders", "Total sales")

```


```{r}
# I applied VAR model to the entire time series with 1st order differenced. 
var.model.order = VARselect(diff_ts, lag.max = 20)
var.model.order$selection
```


```{r}
var.aic.model = VAR(diff_ts, p = 8)
summary(var.aic.model)
```

```{r}
var.bic.model = VAR(diff_ts, p = 1)
summary(var.bic.model)
```

```{r}
## checked residual with order 8 choosen by aic 
plot(ts(residuals(var.aic.model), start = 2000), main = "Residual Processes")
```

```{r}
## checked residual with order 8 choosen by bic 
plot(ts(residuals(var.bic.model), start = 2000), main = "Residual Processes")
```
Statistical test below is for aic order selection

```{r}
serial.test(var.aic.model)
```

P value is bigger than 0.05, fail to reject null of uncorrelated residuals


```{r}
arch.test(var.aic.model)
```

P value is close to 0, reject null of constant volatility


```{r}
normality.test(var.aic.model)
```

P value is close to 0, reject null of normality


Statistical test below is for bic order selection, the result is same as the one from aic. Also, no matter what choosen order is, the roots in within unit circle, so the var model appears to be stable. 


```{r}
serial.test(var.bic.model)
```


```{r}
arch.test(var.bic.model)
```


```{r}
normality.test(var.bic.model)
```


```{r}
granger_causality(var.aic.model)
```


```{r}
granger_causality(var.bic.model)
```

No matter model order chosed by aic or bic, since all p values are bigger than 0.05, there is no significant causal relationship between the variables. 


```{r}
VARselect(diff_ts,type = "both", lag.max = 10, exogen = diff_ts[, 1])$selection
```


## here I tried varx model on the new orders and total sales same time, but got a singular matrix, could not print out summary of the model. 

```{r}
# varx model on both time series.
varx.model = VAR(diff_ts, type = "both", p = 6, exogen = diff_ts[,1])
#summary(varx.model)
```

From the result, I think the value of order we can at most choose is 3. 

















### ARIMA-GARCH model

###(1) First arima garch model is for total sales. 

```{r}
total.sales = ts(newdata[, 2], start = c(2000, 1), freq=12)
new.orders = ts(newdata[, 3], start = c(2000, 1), freq=12)
datte = as.Date(newdata[ ,1], "%m%d%Y")
```

```{r}
par(mfrow = c(2, 1))
plot(total.sales, main = "Time Series of Total Sales", ylab = "Total Sales")
plot(new.orders, main = "Time Series of New Orders", ylab = "New Orders")

```


```{r}
par(mfrow = c(2, 1))
acf(total.sales, main = "ACF of total.sales")
acf(new.orders, main = "ACF of new.orders")
```



```{r}
diff_sales = diff(total.sales)
diff_orders = diff(new.orders)

par(mfrow = c(2, 1))

plot(diff_sales, main = "Differenced Time Series of Total Sales", ylab = "diff")
plot(diff_orders, main = "Differenced Time Series of New Orders", ylab = "diff")
```

```{r}
par(mfrow = c(2, 1))
acf(diff_sales, main = "ACF of Differenced Total sales")
acf(diff_orders, main = "ACF of Differenced New orders")
```

```{r}
correlation_matrix = cor(cbind(total.sales, new.orders))
print(correlation_matrix)
```

```{r}
plot(total.sales, new.orders, pch = 19, col = "lightblue", xlab="Total sales",ylab="New orders")

text(paste("Correlation:", round(cor(total.sales, new.orders), 2)), x = 30, y = 400)
```

```{r}
nfore=9

sales.train=total.sales[1:(length(total.sales)-nfore)]
sales.test=total.sales[((length(total.sales))-nfore):(length(total.sales))]

orders.train=new.orders[1:(length(new.orders)-nfore)]
orders.test=new.orders[((length(new.orders))-nfore):(length(new.orders))]

```


```{r}
test_modelA = function(p,d,q,data){
  mod = arima(data, order=c(p,d,q),method="ML")
  current.aic = AIC(mod)
  df = data.frame(p,d,q,current.aic)
  names(df) = c("p","d","q","AIC")
  #print(paste(p,d,q,current.aic,sep=" "))
  return(df)
}

orders = data.frame(Inf,Inf,Inf,Inf)
names(orders) = c("p","d","q","AIC")

#Orders for DAL
for (p in 0:5){
  for (d in 0:2){
    for (q in 0:5) {
      possibleError = tryCatch(
        orders<-rbind(orders,test_modelA(p,d,q,diff(sales.train))),
        error=function(e) e
      )
      if(inherits(possibleError, "error")) next
      
    }
  }
}
orders = orders[order(-orders$AIC),]
tail(orders,5)
```





```{r}

final.bic = Inf
final.order.sale = c(0,0)
for (p in 0:5) for (q in 0:5) {
    spec = ugarchspec(variance.model=list(garchOrder=c(p,q)),
                      mean.model=list(armaOrder=c(0,1), include.mean=T),
                      distribution.model="std")
    fit = tryCatch({
        ugarchfit(spec, diff(sales.train), solver = 'hybrid')
    }, error = function(e) {
        message("Error fitting model with order (", p, ",", q, "): ", e$message)
        return(NULL)
    })
    
    if (!is.null(fit)) {
        current.bic = infocriteria(fit)[2]
        if (current.bic < final.bic) {
            final.bic = current.bic
            final.order = c(p, q)
        }
    }
}
final.order.sale

```


###  the code above is apply to 1st differenced order of total sales
#### suggested garch order is (0, 0), which will cause an error : degree of freedom needs to be a positive number, so here, i gave an garch order(0,1) which is same as suggest arima order. 

```{r}
#final model for total sales
sales.spec = ugarchspec(variance.model=list(garchOrder=c(0,1)), mean.model=list(armaOrder=c(0,1), include.mean=T), distribution.model="std")
sales.model = ugarchfit(sales.spec, diff(sales.train), solver = 'hybrid')
sales.model
```


```{r}
residuals = residuals(sales.model)
squared_residuals = residuals^2

plot(residuals, main="Residuals of Total sales", type="l")
```

```{r}
plot(squared_residuals, main="Squared Residuals of Total sales", type="l")
```

```{r}
# Autocorrelation: Check for autocorrelation in residuals using ACF
acf(residuals, main="ACF of Residuals of Total sales")
```

```{r}
acf(squared_residuals, main="ACF of Residuals of Total sales")
```

```{r}
pacf(residuals, main="PACF of Residuals of Total sales")
```

```{r}
pacf(squared_residuals, main="PACF of Residuals of Total sales")
```

```{r}
# Ljung-Box test to check for autocorrelation
Box.test(residuals, lag = 4, type = "Ljung-Box")
```

```{r}
Box.test(squared_residuals, lag = 4, type = "Ljung-Box")
```

```{r}
# Alternatively, use Jarque-Bera test for normality
jarque_bera = jarque.bera.test(residuals)
print(jarque_bera)
```

```{r}
# This part is based on BIC on new orders
#allorders.order = function(ts_data, max_p, max_d, max_q){
#  orders = data.frame()
 # for (p in 0:max_p){
 #   for (d in 0:max_d){
 #     for (q in 0:max_q) {
 #       possibleError = tryCatch({
 #         mod = arima(ts_data, order=c(p,d,q), method="ML")
  #        current.bic = BIC(mod)
  #        orders=rbind(orders,c(p,d,q,current.bic))
  #      },
  #        error=function(e) e
   #     )
   #     if(inherits(possibleError, "error")) next
        
   #   }
   # }
  #}
  #names(orders) = c("p","d","q","BIC")
  #return(orders[order(orders$BIC),])
#}
#head(allorders.order(orders.train,8,1,8), 5)


```




## this part is arima garch model on new orders

```{r}
 
test_modelB = function(p,d,q,data){
  mod = arima(data, order=c(p,d,q),method="ML")
  current.aic = AIC(mod)
  df = data.frame(p,d,q,current.aic)
  names(df) = c("p","d","q","AIC")
  #print(paste(p,d,q,current.aic,sep=" "))
  return(df)
}

orders = data.frame(Inf,Inf,Inf,Inf)
names(orders) = c("p","d","q","AIC")

#Orders for DAL
for (p in 0:5){
  for (d in 0:2){
    for (q in 0:5) {
      possibleError = tryCatch(
        orders<-rbind(orders,test_modelB(p,d,q,diff(orders.train))),
        error=function(e) e
      )
      if(inherits(possibleError, "error")) next
      
    }
  }
}
orders = orders[order(-orders$AIC),]
tail(orders,5)

```




### suggested arma order is (5,3), I would choose (4,3) since both aic values are close, 

```{r}
final.bic = Inf
final.order.order = c(0,0)
for (p in 0:5) for (q in 0:5) {
    spec = ugarchspec(variance.model=list(garchOrder=c(p,q)),
                      mean.model=list(armaOrder=c(3,4), include.mean=T),
                      distribution.model="std")
    fit = tryCatch({
        ugarchfit(spec, diff(orders.train), solver = 'hybrid')
    }, error = function(e) {
        message("Error fitting model with order (", p, ",", q, "): ", e$message)
        return(NULL)
    })
    
    if (!is.null(fit)) {
        current.bic = infocriteria(fit)[2]
        if (current.bic < final.bic) {
            final.bic = current.bic
            final.order = c(p, q)
        }
    }
}
final.order.order
```
##### i will work on the solution to this error. 

```{r}
#final model for S2
order.spec = ugarchspec(variance.model=list(garchOrder=c(4,3)), mean.model=list(armaOrder=c(0,0), include.mean=T), distribution.model="std")
order.model = ugarchfit(order.spec, diff(orders.train), solver = 'hybrid')
order.model
```

```{r}
residuals.order = residuals(order.model)
squared_residuals.order = residuals.order^2

plot(residuals.order, main="Residuals of New orders", type="l")
```
```{r}
plot(squared_residuals.order, main="Squared Residuals of New orders", type="l")
```

```{r}
# Autocorrelation: Check for autocorrelation in residuals using ACF
acf(residuals.order, main="ACF of Residuals of New order")
acf(squared_residuals.order, main="ACF of Residuals of New order")
```


```{r}
pacf(residuals.order, main="PACF of Residuals of New orders")
pacf(squared_residuals.order, main="PACF of Residuals of New orders")
```

```{r}
# Ljung-Box test to check for autocorrelation
Box.test(residuals.order, lag = 4, type = "Ljung-Box")
```

```{r}
Box.test(squared_residuals.order, lag = 4, type = "Ljung-Box")
```

```{r}
# Alternatively, use Jarque-Bera test for normality
jarque_bera = jarque.bera.test(residuals.order)
print(jarque_bera)
```


























