---
title: "Proj-Var"
output: html_document
date: "2025-04-23"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


```{r cars}
library(data.table)
library(vars)
library(xts)
library(mgcv)
library(stats)
library(tseries)
library(aod)
library(zoo)
library(lubridate)
library(fGarch)
library(ggpubr)
library(ggfortify)
library(quantmod)
library(urca)
library(forecast)
library(mFilter)
library(TSstudio)
library(tidyverse)
library(bruceR)
library(rugarch)
```



```{r pressure, echo=FALSE}
##### this chunk of the code below is used to identify and remove extreme points
# here i checked extreme points in the original data without convert them to time series. 
data2 = read.csv("VehicleData-1.csv", header = T)
data2$DATE = as.Date(data2$DATE, format =  "%m/%d/%Y")
data2 %>% mutate_all(~replace(., is.nan(.), 0))
```



```{r}
## identify extreme points in the total sales.
max.sales = data2[which.max(data2$Total.Sales), ]
max.sales

min.sales = data2[which.min(data2$Total.Sales), ]
min.sales
```



```{r}
## identify extreme points in the new orders
max.orders = data2[which.max(data2$New.Orders), ]
max.orders

min.orders = data2[which.min(data2$New.Orders), ]
min.orders
```



```{r}
## remove those identified extreme points from total sales and new orders

## remove one max and two min values of tatal sales from dataframe, which is (date) 0001-10-01 and 2020-04-01
data2 = data2[data2$Total.Sales < 22.055,	]
data2 = data2[data2$Total.Sales > 11.736, ]

## first to remove two min values of new orders from dataframe, which is (date) 2020-04-01 since it was during Covid. 
data2 = data2[data2$New.Orders < 64455, ]
data2 = data2[data2$New.Orders > 24561	,	]

head(data2)

# nrow() to find number of points, length to find how many columns.
nrow(data2)

```

The code above is to remove three months from 2020, which are March, Apirl and May, those values are either extreme point or very close to be an extreme points. But in general, I feel the values of sales and orders were generally very low in the year 2020, which still caused a trough even I removed three "extreme" points.which can be seen from the plot below. 



```{r}
## now convert the data with extreme values removed 
new.sales = ts(data2$Total.Sales, start = c(2000,1,1), frequency = 12)
new.orders = ts(data2$New.Orders, start = c(2000,1,1), frequency = 12)
```



```{r}
new.sales.plot = autoplot(new.sales) + xlab("date") + ylab("sales") + ggtitle("Total Sales") 
new.sales.plot

new.orders.plot = autoplot(new.orders) + xlab("data") + ylab("orders") + ggtitle("New Orders")
new.orders.plot
```



```{r}
### since the value of Total sales is seasonally adjusted annual rate, I need to translate the value of new orders to seasonally adjusted annual rate too just to match the total sales with same units.

year = format(data2$DATE, "%y")
new.mean = aggregate(New.Orders~year, data2, mean)

newdata = data.frame(year = new.mean[,1], year_mean = new.mean[,2])
newdata

library(dplyr)
newdata = newdata%>%mutate(month.mean = year_mean/12)
newdata

data2 = data2%>%separate(DATE, c("year", "month", "day"), sep = "-")

split.year = split(data2, data2$year)

```



```{r}
zero = data.frame(data2[data2$year == 0, ])
zero$rate = 0
for (a in 1:length(zero$New.Orders)){
  zero$rate[a] = zero$New.Orders[a]/ 3242.389 
}

one = data.frame(data2[data2$year == 1, ])
one$rate = 0
for (a in 1:length(one$New.Orders)){
  one$rate[a] = one$New.Orders[a]/ 2962.939	
}

two = data.frame(data2[data2$year == 2, ])
two$rate = 0
for (a in 1:length(two$New.Orders)){
  two$rate[a] = two$New.Orders[a]/ 3267.312		
}

three = data.frame(data2[data2$year == 3, ])
three$rate = 0
for (a in 1:length(three$New.Orders)){
  three$rate[a] = three$New.Orders[a]/ 3428.694		
}

four = data.frame(data2[data2$year == 4, ])
four$rate = 0
for (a in 1:length(four$New.Orders)){
  four$rate[a] = four$New.Orders[a]/ 3415.549			
}

five = data.frame(data2[data2$year == 5, ])
five$rate = 0
for (a in 1:length(five$New.Orders)){
  five$rate[a] = five$New.Orders[a]/ 3492.632				
}

six = data.frame(data2[data2$year == 6, ])
six$rate = 0
for (a in 1:length(six$New.Orders)){
  six$rate[a] = six$New.Orders[a]/ 3481.326				
}

seven = data.frame(data2[data2$year == 7, ])
seven$rate = 0
for (a in 1:length(seven$New.Orders)){
  seven$rate[a] = seven$New.Orders[a]/ 3461.674					
}

eight = data.frame(data2[data2$year == 8, ])
eight$rate = 0
for (a in 1:length(eight$New.Orders)){
  eight$rate[a] = eight$New.Orders[a]/ 2996.361					
}

nigh = data.frame(data2[data2$year == 9, ])
nigh$rate = 0
for (a in 1:length(nigh$New.Orders)){
  nigh$rate[a] = nigh$New.Orders[a]/ 2122.000					
}

ten = data.frame(data2[data2$year == 10, ])
ten$rate = 0
for (a in 1:length(ten$New.Orders)){
  ten$rate[a] = ten$New.Orders[a]/ 2890.646						
}

ele = data.frame(data2[data2$year == 11, ])
ele$rate = 0
for (a in 1:length(ele$New.Orders)){
  ele$rate[a] = ele$New.Orders[a]/ 3116.896						
} 

twe = data.frame(data2[data2$year == 12, ])
twe$rate = 0
for (a in 1:length(twe$New.Orders)){
  twe$rate[a] = twe$New.Orders[a]/ 3542.403					
} 

thirteen = data.frame(data2[data2$year == 13, ])
thirteen$rate = 0
for (a in 1:length(thirteen$New.Orders)){
  thirteen$rate[a] = thirteen$New.Orders[a]/ 3791.562					
} 

fourteen = data.frame(data2[data2$year == 14, ])
fourteen$rate = 0
for (a in 1:length(fourteen$New.Orders)){
  fourteen$rate[a] = fourteen$New.Orders[a]/ 4179.000					
} 

fif = data.frame(data2[data2$year == 15, ])
fif$rate = 0
for (a in 1:length(fif$New.Orders)){
  fif$rate[a] = fif$New.Orders[a]/ 4457.993					
} 

sixth = data.frame(data2[data2$year == 16, ])
sixth$rate = 0
for (a in 1:length(sixth$New.Orders)){
  sixth$rate[a] = sixth$New.Orders[a]/ 4449.278						
} 

sev = data.frame(data2[data2$year == 17, ])
sev$rate = 0
for (a in 1:length(sev$New.Orders)){
  sev$rate[a] = sev$New.Orders[a]/ 4418.833						
} 

ei = data.frame(data2[data2$year == 18, ])
ei$rate = 0
for (a in 1:length(ei$New.Orders)){
  ei$rate[a] = ei$New.Orders[a]/ 4641.597						
} 

ni = data.frame(data2[data2$year == 19, ])
ni$rate = 0
for (a in 1:length(ni$New.Orders)){
  ni$rate[a] = ni$New.Orders[a]/ 4545.285							
} 

tw = data.frame(data2[data2$year == 20, ])
tw$rate = 0
for (a in 1:length(tw$New.Orders)){
  tw$rate[a] = tw$New.Orders[a]/ 4507.417							
} 

twone = data.frame(data2[data2$year == 21, ])
twone$rate = 0
for (a in 1:length(twone$New.Orders)){
  twone$rate[a] = twone$New.Orders[a]/ 4389.403							
} 

twtw = data.frame(data2[data2$year == 22, ])
twtw$rate = 0
for (a in 1:length(twtw$New.Orders)){
  twtw$rate[a] = twtw$New.Orders[a]/ 4914.208								
} 

twth = data.frame(data2[data2$year == 23, ])
twth$rate = 0
for (a in 1:length(twth$New.Orders)){
  twth$rate[a] = twth$New.Orders[a]/ 5134.861								
} 

twfour = data.frame(data2[data2$year == 24, ])
twfour$rate = 0
for (a in 1:length(twfour$New.Orders)){
  twfour$rate[a] = twfour$New.Orders[a]/ 5238.583								
} 
```



```{r}
newbind = rbind(zero,one, three,four,five,six,seven,eight,nigh, ten, ele, thirteen, fourteen, fif, sixth,sev, ei, ni, tw, twone, twtw, twth,twfour)

#newbind = newbind%>%mutate(Date.new = make_date(year, month, day))

newbind = newbind%>%mutate(date = ymd(paste(year, month, day)))

newbind$date = as.Date(newbind$date, format =  "%m/%d/%Y")
```



```{r}
newbind = data.frame(newbind)

newdata = data.frame(subset(newbind, select = c(date, Total.Sales, rate)))

colnames(newdata) = c("Date", "SAAR.Total.Sales", "SAAR.New.Orders")

head(newdata)

# check number of data points of dataframe, use nrow(), check number of row of one variable using length()
nrow(newdata)
length(newdata$SAAR.Total.Sales)
length(newdata$SAAR.New.Orders)

new.sales.rate = ts(newdata$SAAR.Total.Sales, start = c(2000,1,1), frequency = 12)
new.orders.rate = ts(newdata$SAAR.New.Orders, start = c(2000,1,1), frequency = 12)

new.sales.rate.plot = autoplot(new.sales.rate) + xlab("Date") + ylab("Total Sales") + ggtitle("Total Sales - Seasonally Adjusted Annual Rate") 
new.sales.rate.plot

new.orders.rate.plot = autoplot(new.orders.rate) + xlab("Date") + ylab("New Orders") + ggtitle("New Orders - Seasonally Adjusted Annual Rate")
new.orders.rate.plot

ts_data = ts(newdata[,-1],start=2000,frequency=12)
autoplot(ts_data,main='SAAR of Total Sales  &  SAAR of New Orders',ylab="SAAR",xlab= 'Date')
```


```{r}
diff_ts = diff(ts_data)
head(diff_ts)
autoplot(diff_ts, main="1st-order Differenced SAAR of Total Sales and New Orders", ylab="1st-order Differenced SAAR", xlab="Date")
```

```{r}
ggAcf(diff_ts[, "SAAR.Total.Sales"], lag.max=200, col="brown1", main="Differenced SAAR of Total Sales")
```


```{r}
ggAcf(diff_ts[, "SAAR.New.Orders"], lag.max=200, col="darkturquoise", main="differenced SAAR of New Orders")
```

(1) From ACFs, I think it is now white noise since most lags are within 95% confidence band, some of the lags are outside the confidence band, due to the rest 5%.
(2) Code below I will start using 1st differenced data, since I think it is a white noise after differencing



### VAR model
```{r}
colnames(diff_ts) = c( "New orders", "Total sales")

```


```{r}
# I applied VAR model to the entire time series with 1st order differenced. 
var.model.order = VARselect(diff_ts, lag.max = 20)
var.model.order$selection
```
```{r}
var.log.model.order = VARselect((diff_ts), lag.max = 20)
```


```{r}
var.aic.model = VAR(diff_ts, p = 8)
summary(var.aic.model)
```

```{r}
var.bic.model = VAR(diff_ts, p = 1)
summary(var.bic.model)
```
result generated from code above suggests order 8 based on aic and order 1 based on bic. according to aic criterion, coefficient of Total.sales.l8 is statistically significant at level 0.05; according to bic criterion, coefficients of both total.sales.l1 and new.orders.l1 are statistically significant at level 0.05. 




```{r}
## checked residual with order 8 choosen by aic 
plot(ts(residuals(var.aic.model), start = 2000), main = "Residual Processes")
```

```{r}
## checked residual with order 8 choosen by bic 
plot(ts(residuals(var.bic.model), start = 2000), main = "Residual Processes")
```

(bic order selection) From plots of residual and squared residual, both implied a white noise. 





##### code below is for statistical test on models with aic and with bic. aic comes first. 

```{r}
serial.test(var.aic.model)
```

P value is bigger than 0.05, fail to reject null of uncorrelated residuals


```{r}
arch.test(var.aic.model)
```

P value is close to 0, reject null of constant volatility


```{r}
normality.test(var.aic.model)
```

P value is close to 0, reject null of normality


Statistical test below is for bic order selection, the result is same as the one from aic. Also, no matter what chosen order is, the roots are in unit circle, so the var model appears to be stable. 


```{r}
serial.test(var.bic.model)
```
P value is smaller than 0.05, reject null of uncorrelated residuals, this result is opposite of the result from aic.



```{r}
arch.test(var.bic.model)
```
P value is close to 0, reject null of constant volatility


```{r}
normality.test(var.bic.model)
```
P value is close to 0, reject null of normality




```{r}
granger_causality(var.aic.model)
```


```{r}
granger_causality(var.bic.model)
```

No matter model order chosed by aic or bic, since all p values are bigger than 0.05, there is no significant causal relationship between the variables. 






#### forecast of VAR model on both variables : plot
```{r}
head(diff_ts)

var.aic.model.forecast = predict(var.aic.model, n.ahead =10)

order.var.aic.pred = var.aic.model.forecast$fcst$New.orders
sales.var.aic.pred = var.aic.model.forecast$fcst$Total.sales

finalpreds=function(fcst,ts){
  var.pred=rep(0,10)
  var.pred[1]=ts[length(ts)]+fcst[1]
  for (i in 2:10){
    var.pred[i]<-var.pred[i-1]+fcst[i]
  }
  return(var.pred)
}

n = nrow(diff_ts)

par(mfrow=c(2,1))

plot(diff_ts[(n-30):n],type="l",ylab="SAAR",xlab="Date",main="Total Sales Predictions")
points(ts(sales.var.aic.pred,start=22),lwd=2,col="red")

plot(diff_ts[(n-30):n],type="l",ylab="SAAR",xlab="Date",main="New Orders Predictions")
points(ts(order.var.aic.pred,start=22),lwd=2,col="blue")

```


```{r}
var.bic.model.forecast = predict(var.bic.model, n.ahead = 10)

order.var.bic.pred = var.bic.model.forecast$fcst$New.orders
sales.var.bic.pred = var.bic.model.forecast$fcst$Total.sales

finalpreds=function(fcst,ts){
  var.pred=rep(0,10)
  var.pred[1]=ts[length(ts)]+fcst[1]
  for (i in 2:10){
    var.pred[i]<-var.pred[i-1]+fcst[i]
  }
  return(var.pred)
}


par(mfrow=c(2,1))

plot(diff_ts[(n-30):n],type="l",ylab="SAAR",xlab="Date",main="Total Sales Predictions")
points(ts(sales.var.bic.pred,start=22),lwd=2,col="red")

plot(diff_ts[(n-30):n],type="l",ylab="SAAR",xlab="Date",main="New Orders Predictions")
points(ts(order.var.bic.pred,start=22),lwd=2,col="blue")


```



#### From the plots above , which are build based on AIC and BIC criterion, since AIC and BIC gave different orders, AIC suggests order 8, BIC suggests order 1. Since the plot shows very little difference on predictions, I would only use the model that built with BIC order 1 to do MAPE and PM.  
#### Forecast of VAR model on both variables : MAPE and PM
```{r}

sales.test=diff_ts[207:247,2]
orders.test = diff_ts[207:247,1]

sales.train=diff_ts[1:206,2]
orders.train = diff_ts[1:206:247,1]

sales.var.pred = finalpreds(sales.var.bic.pred,  sales.train)
orders.var.pred = finalpreds(sales.var.bic.pred, orders.train)

cat("\n\nTotal Sales VAR MAPE:",abs(mean(abs(sales.var.pred-sales.test)/sales.test)),"\nTotal Sales VAR PM:",
sum((sales.var.pred-sales.test)^2)/sum((sales.test-mean(sales.test))^2),
"\nNew Orders MAPE:",abs(mean(abs(orders.var.pred-orders.test)/orders.test)),"\nNew Orders PM:",
sum((orders.var.pred-orders.test)^2)/sum((orders.test-mean(orders.test))^2))
```





#### Code below is for VARX model, import external variables from csv file: AISRSA.

```{r}
external = read.csv("AISRSA.csv", header = T)

#check NA value in the new csv file 
colSums(is.na(external))

external$observation_date = as.Date(external$observation, format =  "%Y-%m-%d")
colnames(external) = c("Date", "Auto.Invertory.Ratio")

external.data = as.data.frame(external[85:379, ])

head(external.data)

```

##### merge two dataframe into one dataframe: new.data

### tried two methods to get exogen works, but failed,   


#### method one 
```{r}

external = read.csv("AISRSA.csv", header = T)

#check NA value in the new csv file 
colSums(is.na(external))

external$observation_date = as.Date(external$observation, format =  "%Y-%m-%d")
colnames(external) = c("Date", "Auto.Invertory.Ratio")

external.data = as.data.frame(external[85:379, ])


new.data = as.data.frame(merge(external.data[37:105, ], newdata[24:92,], by = "Date"))
new.data$Date = as.Date(new.data$Date, format =  "%m/%d/%Y")

inventory.ratio = ts(new.data[ , 2], start = c(2003, 1), freq = 12)
total.sales = ts(new.data[, 3], start = c(2003, 1), freq=12)
new.orders = ts(new.data[, 4], start = c(2003, 1), freq=12)
datte = as.Date(new.data[ ,1], "%m%d%Y")

ts.merge = merge(xts(inventory.ratio, datte), xts(total.sales, datte), xts(new.orders, datte), join = "inner")

colnames(ts.merge) = c("invertory","total.sales", "new.orders")

n = dim(ts.merge)[1]

diff_data = diff(ts.merge)[-1]


train_data_varx = head(diff_data, -6)
test_data_varx = tail(diff_data, 6)


VARselect(train_data_varx[, -1], type = "both", lag.max = 9, exogen = train_data_varx[, 1])$selection

varx.model = VAR(train_data_varx[,-1], type = "both", p = 5,exogen = train_data_varx[, 1])
summary(varx.model)


```

#### method two 

```{r}
external.one = read.csv("AISRSA.csv", header = T)

external.one$observation_date = as.Date(external.one$observation, format =  "%Y-%m-%d")
colnames(external.one) = c("Date", "Auto.Invertory.Ratio")

external.data = data.frame(external.one[85:379, ])

head(external.data)

new.data = as.data.frame(merge(external.data[37:105, ], newdata[24:92,], by = "Date"))
new.data$Date = as.Date(new.data$Date, format =  "%m/%d/%Y")

inventory.ratio.one = diff(new.data[,2])
total.sales.one = diff(new.data[, 3])
new.orders.one = diff(new.data[, 4])
data.diff.one = data.frame(cbind(inventory.ratio.one, total.sales.one, new.orders.one))

throught.diff.train = data.diff.one$inventory.ratio.one

data.varx.select = VARselect(data.diff.one[,-2], type="both", exogen = data.diff.one[, 2])
data.varx.select$selection

varx.model = VAR(data.diff.one[,-2], type = "both", p = 2, exogen = data.diff.one[, 2])
#summary(varx.model)
```










#### I have tried VARX model with both being exogenous separately in difference varx model order selectionand VAR() with each being exoge one time, but when i tried to display the model, summary() failed, as it said the matrix is singular. so instead, i only display model without summary(), then I only coefficient of the model with each being exogenous variable one time. when new orders being exogenous variable, I got all coefficient 0 for equation new orders. I am not sure what conclusion we can have from this, does it mean new orders is exogenous variable and determined outside the model? 















### ARIMA-GARCH model

###(1) First arima garch model is for total sales. 

```{r}
total.sales = ts(newdata[, 2], start = c(2000, 1), freq=12)
new.orders = ts(newdata[, 3], start = c(2000, 1), freq=12)
datte = as.Date(newdata[ ,1], "%m%d%Y")
```

```{r}
par(mfrow = c(2, 1))
plot(total.sales, main = "Time Series of Total Sales", ylab = "Total Sales")
plot(new.orders, main = "Time Series of New Orders", ylab = "New Orders")

```


```{r}
par(mfrow = c(2, 1))
acf(total.sales, main = "ACF of total.sales")
acf(new.orders, main = "ACF of new.orders")
```



```{r}
diff_sales = diff(total.sales)
diff_orders = diff(new.orders)

par(mfrow = c(2, 1))

plot(diff_sales, main = "Differenced Time Series of Total Sales", ylab = "diff")
plot(diff_orders, main = "Differenced Time Series of New Orders", ylab = "diff")
```

```{r}
par(mfrow = c(2, 1))
acf(diff_sales, main = "ACF of Differenced Total sales")
acf(diff_orders, main = "ACF of Differenced New orders")
```

```{r}
correlation_matrix = cor(cbind(total.sales, new.orders))
print(correlation_matrix)
```

```{r}
plot(total.sales, new.orders, pch = 19, col = "lightblue", xlab="Total sales",ylab="New orders")

text(paste("Correlation:", round(cor(total.sales, new.orders), 2)), x = 30, y = 400)
```

```{r}
nfore=9

sales.train=total.sales[1:(length(total.sales)-nfore)]
sales.test=total.sales[((length(total.sales))-nfore):(length(total.sales))]

orders.train=new.orders[1:(length(new.orders)-nfore)]
orders.test=new.orders[((length(new.orders))-nfore):(length(new.orders))]

```



### First is arima model on total sales, arima garch on total sales positioned below the arima model, all with 1st differencing order.
```{r}
test_modelA = function(p,d,q,data){
  mod = arima(data, order=c(p,d,q),method="ML")
  current.aic = AIC(mod)
  df = data.frame(p,d,q,current.aic)
  names(df) = c("p","d","q","AIC")
  #print(paste(p,d,q,current.aic,sep=" "))
  return(df)
}

orders = data.frame(Inf,Inf,Inf,Inf)
names(orders) = c("p","d","q","AIC")

#Orders for DAL
for (p in 0:5){
  for (d in 0:2){
    for (q in 0:5) {
      possibleError = tryCatch(
        orders<-rbind(orders,test_modelA(p,d,q,diff(sales.train))),
        error=function(e) e
      )
      if(inherits(possibleError, "error")) next
      
    }
  }
}
orders = orders[order(-orders$AIC),]
tail(orders,5)
```


```{r}
final.bic = Inf
final.order.sale = c(0,0)
for (p in 0:5) for (q in 0:5) {
    spec = ugarchspec(variance.model=list(garchOrder=c(p,q)),
                      mean.model=list(armaOrder=c(0,1), include.mean=T),
                      distribution.model="std")
    fit = tryCatch({
        ugarchfit(spec, diff(sales.train), solver = 'hybrid')
    }, error = function(e) {
        message("Error fitting model with order (", p, ",", q, "): ", e$message)
        return(NULL)
    })
    
    if (!is.null(fit)) {
        current.bic = infocriteria(fit)[2]
        if (current.bic < final.bic) {
            final.bic = current.bic
            final.order = c(p, q)
        }
    }
}
final.order.sale
```


```{r}
arima.sale.model = arima(diff(sales.train), order = c(0,0,1), method = "ML")
```

```{r}
par(mfrow=c(2,2))

acf(resid(arima.sale.model), 
    main = "ACF of Residuals (Total Sales)", 
    cex.main = 0.7)

pacf(resid(arima.sale.model),
    main = "PACF of Residuals (Total Sales)", 
    cex.main = 0.7)


acf(resid(arima.sale.model)^2, 
    main = "ACF of Squared Residuals (Total Sales)", 
    cex.main = 0.7)

pacf(resid(arima.sale.model)^2, 
    main = "PACF of Squared Residuals (Total Sales)", 
    cex.main = 0.7)
```


```{r}
Box.test(arima.sale.model$residuals, lag = (0+1+1), 
         type="Ljung-Box", fitdf = (0+1))
```
P value is much bigger than 0.05, fail to reject null of independently distributed



```{r}
Box.test(arima.sale.model$residuals^2, lag = (0+1+1), 
         type="Ljung-Box", fitdf = (0+1))
```
P value is smaller than 0.05, reject null of independently distributed


```{r}
train_sales = total.sales[1:(length(total.sales)-5)]
test_sales = total.sales[(length(total.sales)-4):length(total.sales)]

n = length(total.sales)
n_fit=length(train_sales)
n_forward=n-n_fit
w_n=length(train_sales)

outpred_sales= predict(arima.sale.model,n.ahead=n_forward)

# 95% confidence interval
ubound_sales = outpred_sales$pred+1.96*outpred_sales$se
lbound_sales = outpred_sales$pred-1.96*outpred_sales$se
ymin = min(lbound_sales)-100
ymax = max(ubound_sales)+100

dates.diff = newdata$Date

par(mfrow=c(1,1))

plot((dates.diff)[(n-n_forward-20):n],total.sales[(n-n_forward-20):n], main = "Forecast on Total Sales", type="l",
     ylim=c(ymin,ymax), xlab="Date", ylab="SAAR of Total Sales")
points((dates.diff)[(n_fit+1):n],outpred_sales$pred,col="red")
lines((dates.diff)[(n_fit+1):n],ubound_sales,lty=3,lwd= 2, col="blue")
lines((dates.diff)[(n_fit+1):n],lbound_sales,lty=3,lwd= 2, col="blue")
#legend('topleft', legend=c("1 month ahead ","Upper-Lower bound"), lty = 2, col=c("red","blue"))

```


```{r}
n_w = length(total.sales)
val_true_sales = as.vector(total.sales[(n_fit+1):n_w])
val_pred_sales = outpred_sales$pred
```


```{r}
#cat("\n\nTotal Sales ARIMA MAPE:",abs(mean(abs(val_pred_sales-val_true_sales)/val_true_sales)),"\nTotal Sales ARIMA PM:",
#sum((val_pred_sales-val_true_sales)^2)/sum((val_true_sales)^2),
#"\nNew Orders MAPE:",abs(mean(abs(orders.var.pred-orders.test)/orders.test)),"\nNew Orders PM:",
#sum((orders.var.pred-orders.test)^2)/sum((orders.test-mean(orders.test))^2))
```


###  the code above is applied to 1st differenced order of total sales



#### suggested garch order is (0, 0), which will cause an error : degree of freedom needs to be a positive number, so here, i gave an garch order(0,1) which is same as suggest arima order. 

```{r}
#final model for total sales
sales.spec = ugarchspec(variance.model=list(model = "eGARCH", submodel = "EGARCH",garchOrder=c(0,1)), mean.model=list(armaOrder=c(0,1), include.mean=T), distribution.model="std")
sales.model = ugarchfit(sales.spec, diff(sales.train), solver = 'hybrid')
sales.model
```


```{r}
residuals = residuals(sales.model)
squared_residuals = residuals^2

plot(residuals, main="Residuals of Total sales", type="l")
```

```{r}
plot(squared_residuals, main="Squared Residuals of Total sales", type="l")
```

```{r}
# Autocorrelation: Check for autocorrelation in residuals using ACF
acf(residuals, main="ACF of Residuals of Total sales")
```

```{r}
acf(squared_residuals, main="ACF of Squared Residuals of Total sales")
```

```{r}
pacf(residuals, main="PACF of Residuals of Total sales")
```

```{r}
pacf(squared_residuals, main="PACF of Squared Residuals of Total sales")
```

```{r}
# Ljung-Box test to check for autocorrelation
Box.test(residuals, lag = 4, type = "Ljung-Box")
```
p value is bigger than 0.05, fail to reject null of independently distributed




```{r}
Box.test(squared_residuals, lag = 4, type = "Ljung-Box")
```
p value is smaller than 0.05, reject null of independently distributed




```{r}
# Alternatively, use Jarque-Bera test for normality
jarque_bera = jarque.bera.test(residuals)
print(jarque_bera)
```
P value is smaller than 0.05, reject null of data being normally distributed












## This part is arima model on new orders. arima garch model positioned below arima model. 

```{r}
 
test_modelB = function(p,d,q,data){
  mod = arima(data, order=c(p,d,q),method="ML")
  current.aic = AIC(mod)
  df = data.frame(p,d,q,current.aic)
  names(df) = c("p","d","q","AIC")
  #print(paste(p,d,q,current.aic,sep=" "))
  return(df)
}

orders = data.frame(Inf,Inf,Inf,Inf)
names(orders) = c("p","d","q","AIC")

#Orders for DAL
for (p in 0:5){
  for (d in 0:2){
    for (q in 0:5) {
      possibleError = tryCatch(
        orders<-rbind(orders,test_modelB(p,d,q,diff(orders.train))),
        error=function(e) e
      )
      if(inherits(possibleError, "error")) next
      
    }
  }
}
orders = orders[order(-orders$AIC),]
tail(orders,5)

```



### suggested arma order is (0,2) 

```{r}
final.bic = Inf
final.order.order = c(0,0)
for (p in 0:5) for (q in 0:5) {
    spec = ugarchspec(variance.model=list(garchOrder=c(p,q)),
                      mean.model=list(armaOrder=c(0,2), include.mean=T),
                      distribution.model="std")
    fit = tryCatch({
        ugarchfit(spec, diff(orders.train), solver = 'hybrid')
    }, error = function(e) {
        message("Error fitting model with order (", p, ",", q, "): ", e$message)
        return(NULL)
    })
    
    if (!is.null(fit)) {
        current.bic = infocriteria(fit)[2]
        if (current.bic < final.bic) {
            final.bic = current.bic
            final.order = c(p, q)
        }
    }
}
final.order.order
```


#### (arima garch order selection on differenced New orders)From order selection, based on AIC criterion, the selected order for arima-garch is (0,2) x (0,0), i will fit an arima model 

```{r}

arima.order.model = arima(orders.train, order = c(0,1,2), method = "ML")
```

```{r}
par(mfrow=c(2,2))

acf(resid(arima.order.model), 
    main = "ACF of Residuals (New Orders)", 
    cex.main = 0.7)

pacf(resid(arima.order.model),
    main = "PACF of Residuals (New Orders)", 
    cex.main = 0.7)


acf(resid(arima.order.model)^2, 
    main = "ACF of Squared Residuals (New Orders)", 
    cex.main = 0.7)

pacf(resid(arima.order.model)^2, 
    main = "PACF of Squared Residuals (New Orders)", 
    cex.main = 0.7)
```

```{r}
Box.test(arima.order.model$residuals, lag = (0+2+1), 
         type="Ljung-Box", fitdf = (0+2))
```
P value is bigger than 0.05,  fail to reject the null of independently distributed


```{r}
Box.test(arima.order.model$residuals^2, lag = (0+2+1), 
         type="Ljung-Box", fitdf = (0+2))
```

P value is smaller than 0.05,  reject the null of independently distributed





```{r}

train_orders = new.orders[1:(length(new.orders)-5)]
test_orders = new.orders[(length(new.orders)-4):length(new.orders)]

n = length(new.orders)
n_fit=length(train_orders)
n_forward=n-n_fit
w_n=length(train_orders)

outpred_orders= predict(arima.order.model,n.ahead=n_forward)

# 95% confidence interval
ubound = outpred_orders$pred+1.96*outpred_orders$se
lbound = outpred_orders$pred-1.96*outpred_orders$se
ymin = min(lbound)-100
ymax = max(ubound)+100

dates.diff = newdata$Date

par(mfrow=c(1,1))

n = length(new.orders)

plot((dates.diff)[(n-n_forward-20):n],new.orders[(n-n_forward-20):n], main = "Forecast on New Orders", type="l",
     ylim=c(ymin,ymax), xlab="Date", ylab="SAAR of New Ordes")
points((dates.diff)[(n_fit+1):n],outpred_orders$pred,col="red")
lines((dates.diff)[(n_fit+1):n],ubound,lty=3,lwd= 2, col="blue")
lines((dates.diff)[(n_fit+1):n],lbound,lty=3,lwd= 2, col="blue")
#legend('topleft', legend=c("9 month ahead ","Upper-Lower bound"), lty = 2, col=c("red","blue"))
```


```{r}
n_w = length(new.orders)
val_true_orders = as.vector(new.orders[(n_fit+1):n_w])
val_pred_orders = outpred_orders$pred
```


```{r}
cat("\n\nTotal Sales ARIMA MAPE:",abs(mean(abs(val_pred_sales-val_true_sales)/val_true_sales)),"\nTotal Sales ARIMA PM:",
sum((val_pred_sales-val_true_sales)^2)/sum((val_true_sales)^2),
"\nNew Orders ARIMA MAPE:",abs(mean(abs(val_pred_orders-val_true_orders)/val_true_orders)),"\nNew Orders ARIMA PM:",
sum((val_pred_orders-val_true_orders)^2)/sum((val_true_orders)^2))
```








###### Down below is the arima garch model with garch order (0,0) (1st differnced order on New orders)
```{r}
#final model for orders
order.spec = ugarchspec(variance.model=list(model = "eGARCH", submodel = "EGARCH",garchOrder=c(0,1)), mean.model=list(armaOrder=c(0,2), include.mean=T), distribution.model="std")
order.model = ugarchfit(order.spec, diff(orders.train), solver = 'hybrid')
order.model
```


```{r}
residuals.order = residuals(order.model)
squared_residuals.order = residuals.order^2

plot(residuals.order, main="Residuals of New orders", type="l")

plot(squared_residuals.order, main="Squared Residuals of New orders", type="l")
```


```{r}
# Autocorrelation: Check for autocorrelation in residuals using ACF
acf(residuals.order, main="ACF of Residuals of New order")
acf(squared_residuals.order, main="ACF of Squared Residuals of New order")
```


```{r}
pacf(residuals.order, main="PACF of Residuals of New orders")
pacf(squared_residuals.order, main="PACF of Squared Residuals of New orders")
```

```{r}
# Ljung-Box test to check for autocorrelation
Box.test(residuals.order, lag = 4, type = "Ljung-Box")
```

P value is bigger than 0.05, fail to reject null of independently distributed



```{r}
Box.test(squared_residuals.order, lag = 4, type = "Ljung-Box")
```
P value is smaller than 0.05, reject null of independently distributed





```{r}
# Alternatively, use Jarque-Bera test for normality
jarque_bera = jarque.bera.test(residuals.order)
print(jarque_bera)
```
P value is smaller than 0.05, reject null of data being normally distributed.






















