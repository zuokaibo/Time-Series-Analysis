---
title: "Untitled"
author: "TSA Pro-2"
date: "2025-04-15"
output:
  html_document: default
  pdf_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
library(mgcv)
library(ggplot2)
library(ggfortify)
library(TSA)
library(dynlm)
library(stats)
library(PerformanceAnalytics)
library(fable)
library(reshape2)
library(astsa)
library(forecast)
library(tidyverse)
library(rugarch)
```

```{r}
data = read.csv("VehicleData-1.csv", header = T)
data$DATE = as.Date(data$DATE, format =  "%m/%d/%Y")

data %>% mutate_all(~replace(., is.nan(.), 0))

head(data)

sales = ts(data$Total.Sales, start = c(2000,1,1), frequency = 12 )
orders = ts(data$New.Orders, start = c(2000,1,1), frequency = 12)

```


```{r}
sales.plot = autoplot(sales) + xlab("date") + ylab("sales") + ggtitle("Total Sales")
sales.plot

orders.plot = autoplot(orders) + xlab("data") + ylab("orders") + ggtitle("New Orders")
orders.plot

newplots = cbind(sales, orders)
new.plots = autoplot(newplots, facets = F) + scale_y_continuous(trans = "log10")
new.plots
```

```{r}
acf(sales, lag.max = 200)
pacf(sales, lag.max = 200)

acf(orders, lag.max = 100)
pacf(orders, lag.max = 100)

##### (not sure if code below is correct, to check a relation between two univariate time series variables)

## checking relation between new orders and total sales within 12 month.
total.sales  = as.numeric(sales)
new.orders = as.numeric(orders)
#astsa::lag2.plot(new.orders, total.sales, 12)

## checking correlation coefficient between two time series variables: new orders and total sales
ccf(new.orders, total.sales, lag.max = 50)
```

```{r}

sales = ts(data$Total.Sales, start = c(2000,1,1), frequency = 12)
orders = ts(data$New.Orders, start = c(2000,1,1), frequency = 12)

## X-axis points converted to 0-1 scale
sales.time.pts = c(1:length(sales))
sales.time.pts = c(sales.time.pts - min(sales.time.pts))/max(sales.time.pts)

orders.time.pts = c(1:length(orders))
orders.time.pts = c(orders.time.pts - min(orders.time.pts))/max(orders.time.pts)

## Splines Trend Estimation on sales
sales.spline = gam(sales~s(sales.time.pts))
sales.spline.fit = ts(fitted(sales.spline),start=2000,frequency=12)

## Splines Trend Estimation on orders
orders.spline = gam(orders~s(orders.time.pts))
orders.spline.fit = ts(fitted(orders.spline), start = 2000, frequency = 12)


## plot trends, but doesnt show up in the plot, need to fix this . 

## add trend to total sales 
ts.plot(sales,ylab="Total Sales", main = "Total sales with Fitted Spline")
lines(sales.spline.fit, lwd=2,col="darkred")
#abline(sales.spline.fit[1],0,lwd=2,col="blue")

## add trend to new orders
ts.plot(orders,ylab="New Orders", main = "New orders with Fitted Spline")
lines(orders.spline.fit,lwd=2,col="brown")
#abline(orders.spline.fit[1],0,lwd=2,col="blue")
```

```{r}
par(mfrow=c(1,2))
hist(sales)
hist(orders)
```

```{r}
par(mfrow=c(1,2))
hist(log(sales + 1))
hist(log(orders + 1))
```

```{r}

sales.spline.log = gam(log(sales + 1)~s(sales.time.pts))
sales.spline.fit.log = ts(fitted(sales.spline.log),start=2000,frequency=12)

ts.plot(log(sales + 1),ylab="Total Sales", main = "Total sales with Fitted Spline")
lines(sales.spline.fit.log, lwd=2,col="darkred")


orders.spline.log = gam(log(orders + 1)~s(orders.time.pts))
orders.spline.fit.log = ts(fitted(orders.spline.log), start = 2000, frequency = 12)

## add trend to new orders
ts.plot(log(orders + 1),ylab="New Orders", main = "New orders with Fitted Spline")
lines(orders.spline.fit.log,lwd=2,col="brown")
```




```{r}
## check seasonlity on sales
sales.model1=lm(sales~harmonic(sales))
summary(sales.model1)

sales.model2=lm(sales~harmonic(sales,2))
summary(sales.model2)

## check seasonlity on sales
orders.model1=lm(orders~harmonic(orders))
summary(orders.model1)

orders.model2=lm(orders~harmonic(orders,2))
summary(orders.model2)

```

```{r}
## Fit a non-parametric model for trend and linear model for seasonality on total sales
sales.har = harmonic(sales,2)
sales.gam.fit = gam(sales~s(sales.time.pts)+sales.har)
sales.dif.fit.gam = ts((sales-fitted(sales.gam.fit)),start=2000,frequency=12)
ts.plot(sales.dif.fit.gam,ylab="residual", main="Residual Process on Total sales")

## Fit a non-parametric model for trend and linear model for seasonality on new orders
orders.har = harmonic(orders,2)
orders.gam.fit = gam(orders~s(orders.time.pts)+orders.har)
orders.dif.fit.gam = ts((orders-fitted(orders.gam.fit)),start=2000,frequency=12)
ts.plot(orders.dif.fit.gam,ylab="residual", main="Residual Process on New orders")
```

```{r}
##  fitting arima model on sales 

## differencing with order 1
new.data.sales = sales

# 60 is the 20% of length of sales
sales.train = new.data.sales[1:(length(new.data.sales) - 60)]
sales.test = new.data.sales[(length(new.data.sales)- 60 + 1) : length(new.data.sales)]
# reference: lecture notes from module 2
n = length(sales.train)
norder = 7
p = c(1:norder)-1
q = c(1:norder)-1

aic = matrix(0, norder, norder)

# differencing with order 1
for (i in 1:norder) {
  for (j in 1:norder) {
    modij = arima(sales.train, order=c(p[i], 1, q[j]), method = "ML", include.mean = FALSE)
    aic[i, j] = modij$aic + 2 * (p[i] + q[j] +1)  * (p[i] + q[j]) / (n - p[i] - q[j] - 1)
  } 
}

indexp = rep(c(1:norder),norder)
indexq = rep(c(1:norder),each=norder)
indexaic = which(aic == min(aic))
porder = indexp[indexaic]-1
qorder = indexq[indexaic]-1
porder 
qorder

sales.final.diff.one = arima(sales.train, order = c(porder, 1, qorder), method = "ML")
sales.final.diff.one

```

```{r}
##  fitting arima model on orders 

## differencing with order 1
new.data.orders = orders

# 60 is the 20% of length of sales
orders.train = new.data.orders[1:(length(new.data.orders) - 60)]
orders.test = new.data.orders[(length(new.data.orders)- 60 + 1) : length(new.data.orders)]
# reference: lecture notes from module 2
n = length(orders.train)
norder = 7
p = c(1:norder)-1
q = c(1:norder)-1

aic = matrix(0, norder, norder)

# differencing with order 1
for (i in 1:norder) {
  for (j in 1:norder) {
    modij = arima(orders.train, order=c(p[i], 1, q[j]), method = "ML", include.mean = FALSE)
    aic[i, j] = modij$aic + 2 * (p[i] + q[j] +1)  * (p[i] + q[j]) / (n - p[i] - q[j] - 1)
  } 
}

indexp = rep(c(1:norder),norder)
indexq = rep(c(1:norder),each=norder)
indexaic = which(aic == min(aic))
porder = indexp[indexaic]-1
qorder = indexq[indexaic]-1
porder 
qorder

orders.final.diff.one = arima(orders.train, order = c(porder, 1, qorder), method = "ML")
orders.final.diff.one
```

```{r}
## arima evaluation on sales
sales.resid = resid(sales.final.diff.one)
plot(sales.resid, main = "Residual plot of total sales ( p =  3 & q = 0)")
acf(sales.resid, lag.max = 200,  main = "Residual ACF of total sales ( p =  3 & q = 0)")
pacf(sales.resid, lag.max = 200, main = "Residual PACF of total sales ( p =  3 & q = 0)")
Box.test(sales.resid, lag = ( 0+3+1 ), type = "Ljung-Box", fitdf = (0+3))


## arima evaluation on orders
orders.resid = resid(sales.final.diff.one)
plot(orders.resid, main = "Residual plot of New orders ( p =  5 & q = 6)")
acf(orders.resid, lag.max = 200,  main = "Residual ACF of new orders ( p =  5 & q = 6)")
pacf(orders.resid, lag.max = 200, main = "Residual PACF of new orders ( p =  5 & q = 6)")
Box.test(orders.resid, lag = ( 5+6+1 ), type = "Ljung-Box", fitdf = (5+6))
```

```{r}
## checking garch order on Total sales with p = 3, q = 0, d= 1
final.bic = Inf
final.order = c(0,0)
sales.test.garch = function(m, n) {
  spec = ugarchspec(variance.model = list(garchOrder = c(m, n)), mean.model = list(armaOrder=c(3,0),include.mean = T), distribution.model = "std")
  fit = ugarchfit(spec, sales.train, solver= "hybrid")
  current.bic = infocriteria(fit)[2]
  bicdata = data.frame(m,n,current.bic)
  names(bicdata) = c("m","n","BIC")
  print(paste(m,n,current.bic, sep=" "))
  return(bicdata)
}

orders = data.frame(Inf, Inf, Inf)
names(orders) = c("m", "n", "BIC")

for (m in 0:2) for (n in 0:2) {
  Error = tryCatch(orders = rbind(orders, sales.test.garch(m, n)), error = function(e) e) 
  if (inherits(Error, "error"))
    next
}
```

```{r}
## checking garch order on New orders  with p = 3, q = 0, d= 1
final.bic = Inf
final.order = c(0,0)
orders.test.garch = function(m, n) {
  spec = ugarchspec(variance.model = list(garchOrder = c(m, n)), mean.model = list(armaOrder=c(5,6),include.mean = T), distribution.model = "std")
  fit = ugarchfit(spec, orders.train, solver= "hybrid")
  current.bic = infocriteria(fit)[2]
  #garchforecast = ugarchforecast(fitORspec = fit, n.ahead = orders.test)
  bicdata = data.frame(m,n,current.bic)
  names(bicdata) = c("m","n","BIC")
  print(paste(m,n,current.bic, sep=" "))
  return(bicdata)
}

order = data.frame(Inf, Inf, Inf)
names(order) = c("m", "n", "BIC")

for (m in 0:2) for (n in 0:2) {
  Error = tryCatch(order = rbind(orders, orders.test.garch(m, n)), error = function(e) e) 
  if (inherits(Error, "error"))
    next
}
```

```{r}
## fit optimal orders in arma garch model (Total sales)
garchspec.sales = ugarchspec(variance.model = list(garchOrder = c(1,0)), mean.model = list(armaOrder = c(3,0),include.mean = T), distribution.model = "std")

garchfit.sales = ugarchfit(garchspec.sales, sales.train, solver="hybrid")

garchforecast.sales = ugarchforecast(fitORspec = garchfit.sales, n.ahead = 100)

## predicted mean
garchmean.sales = fitted(garchfit.sales)
#garchmean

## predicted volatilities
garchvola.sales = sigma(garchfit.sales)
#garchvola
plot(garchvola.sales, main = "volatilities of Total sales")
```

```{r}
## fit optimal orders in arma garch model (New orders)
garchspec.orders = ugarchspec(variance.model = list(garchOrder = c(1,1)), mean.model = list(armaOrder = c(5,6),include.mean = T), distribution.model = "std")

garchfit.orders = ugarchfit(garchspec.orders, orders.train, solver="hybrid")

garchforecast.orders = ugarchforecast(fitORspec = garchfit.orders, n.ahead = 100)

## predicted mean
garchmean.orders = fitted(garchfit.orders)
#garchmean

## predicted volatilities
garchvola.orders = sigma(garchfit.orders)
#garchvola
plot(garchvola.orders, main = "Volatilities of New Orders")
```

```{r}
cor(garchvola.sales,garchvola.orders)
```







### The part below is multivariate time series. 

```{r}
library(data.table)
library(vars)
library(xts)
library(mgcv)
library(stats)
library(tseries)
library(aod)
library(zoo)
library(lubridate)
library(fGarch)
library(ggpubr)
library(ggfortify)
library(quantmod)
library(urca)
library(forecast)
library(mFilter)
library(TSstudio)
library(tidyverse)
library(bruceR)
```


####### 
(1)I checked plots of total sales and new orders from original data. 
(3)Identify max and min values in total sales and new orders. the min values in total sales and new orders happened to be on the same date 2020-04-01.
(2)I gave dataframe a new name data2 (just incase in later we might need some variables that i built under original dataframe called data.), I have removed max and min values in the total sales, the date is 0001-10-01 and 2020-04-01, also removed min value of new orders but not max value of new orders, since the min value appeared during covid, but could not find a reason to remove max value.
(4)Compare the output from the code with the value in the plots of total sales and new orders. they seemed match each other. so i kept the data2 with the extreme values in total sales and new orders removed. 



```{r}
#sales.plot = autoplot(sales) + xlab("date") + ylab("sales") + ggtitle("Total Sales")
#sales.plot

#orders.plot = autoplot(orders) + xlab("data") + ylab("orders") + ggtitle("New Orders")
#orders.plot

#newplots = cbind(sales, orders)
#new.plots = autoplot(newplots, facets = F) + scale_y_continuous(trans = "log10")
#new.plots

```


```{r}
##### this chunk of the code below is used to identify and remove extreme points

# here i checked extreme points in the original data without convert them to time series. 
data2 = read.csv("VehicleData-1.csv", header = T)
data2$DATE = as.Date(data$DATE, format =  "%m/%d/%Y")
data2 %>% mutate_all(~replace(., is.nan(.), 0))
```


```{r}
## identify extreme points in the total sales.
max.sales = data2[which.max(data2$Total.Sales), ]
max.sales

min.sales = data2[which.min(data2$Total.Sales), ]
min.sales
```


```{r}
## identify extreme points in the new orders
max.orders = data2[which.max(data2$New.Orders), ]
max.orders

min.orders = data2[which.min(data2$New.Orders), ]
min.orders
```


```{r}
## remove those identified extreme points from total sales and new orders

## remove one max and two min values of tatal sales from dataframe, which is (date) 0001-10-01 and 2020-04-01
data2 = data2[data2$Total.Sales < 22.055,	]
data2 = data2[data2$Total.Sales > 11.736, ]

## first to remove two min values of new orders from dataframe, which is (date) 2020-04-01 since it was during Covid. 
data2 = data2[data2$New.Orders < 64455, ]
data2 = data2[data2$New.Orders > 24561	,	]

head(data2)

# nrow() to find number of points, length to find how many columns.
nrow(data2)

```
The code above is to remove three months from 2020, which are March, Apirl and May, those values are either extreme point or very close to be an extreme points. But in general, I feel the values of sales and orders were generally very low in the year 2020, which still caused a trough even I removed three "extreme" points.which can be seen from the plot below. 


```{r}
## now convert the data with extreme values removed 
new.sales = ts(data2$Total.Sales, start = c(2000,1,1), frequency = 12)
new.orders = ts(data2$New.Orders, start = c(2000,1,1), frequency = 12)

```

```{r}
new.sales.plot = autoplot(new.sales) + xlab("date") + ylab("sales") + ggtitle("Total Sales") 
new.sales.plot

new.orders.plot = autoplot(new.orders) + xlab("data") + ylab("orders") + ggtitle("New Orders")
new.orders.plot

```

```{r}
### since the value of Total sales is seasonally adjusted annual rate, I need to translate the value of new orders to seasonally adjusted annual rate too just to match the total sales with same units.

year = format(data2$DATE, "%y")
new.mean = aggregate(New.Orders~year, data2, mean)
#new.mean[,1]
#new.mean[,2]
newdata = data.frame(year = new.mean[,1], year_mean = new.mean[,2])
newdata

library(dplyr)
newdata = newdata%>%mutate(month.mean = year_mean/12)
newdata
data2 = data2%>%separate(DATE, c("year", "month", "day"), sep = "-")

split.year = split(data2, data2$year)

data2

```

```{r}
zero = data.frame(data2[data2$year == 0, ])
zero$rate = 0
for (a in 1:length(zero$New.Orders)){
  zero$rate[a] = zero$New.Orders[a]/ 3242.389 
}

one = data.frame(data2[data2$year == 1, ])
one$rate = 0
for (a in 1:length(one$New.Orders)){
  one$rate[a] = one$New.Orders[a]/ 2962.939	
}

two = data.frame(data2[data2$year == 2, ])
two$rate = 0
for (a in 1:length(two$New.Orders)){
  two$rate[a] = two$New.Orders[a]/ 3267.312		
}

three = data.frame(data2[data2$year == 3, ])
three$rate = 0
for (a in 1:length(three$New.Orders)){
  three$rate[a] = three$New.Orders[a]/ 3428.694		
}

four = data.frame(data2[data2$year == 4, ])
four$rate = 0
for (a in 1:length(four$New.Orders)){
  four$rate[a] = four$New.Orders[a]/ 3415.549			
}

five = data.frame(data2[data2$year == 5, ])
five$rate = 0
for (a in 1:length(five$New.Orders)){
  five$rate[a] = five$New.Orders[a]/ 3492.632				
}

six = data.frame(data2[data2$year == 6, ])
six$rate = 0
for (a in 1:length(six$New.Orders)){
  six$rate[a] = six$New.Orders[a]/ 3481.326				
}

seven = data.frame(data2[data2$year == 7, ])
seven$rate = 0
for (a in 1:length(seven$New.Orders)){
  seven$rate[a] = seven$New.Orders[a]/ 3461.674					
}

eight = data.frame(data2[data2$year == 8, ])
eight$rate = 0
for (a in 1:length(eight$New.Orders)){
  eight$rate[a] = eight$New.Orders[a]/ 2996.361					
}

nigh = data.frame(data2[data2$year == 9, ])
nigh$rate = 0
for (a in 1:length(nigh$New.Orders)){
  nigh$rate[a] = nigh$New.Orders[a]/ 2122.000					
}

ten = data.frame(data2[data2$year == 10, ])
ten$rate = 0
for (a in 1:length(ten$New.Orders)){
  ten$rate[a] = ten$New.Orders[a]/ 2890.646						
}

ele = data.frame(data2[data2$year == 11, ])
ele$rate = 0
for (a in 1:length(ele$New.Orders)){
  ele$rate[a] = ele$New.Orders[a]/ 3116.896						
} 

twe = data.frame(data2[data2$year == 12, ])
twe$rate = 0
for (a in 1:length(twe$New.Orders)){
  twe$rate[a] = twe$New.Orders[a]/ 3542.403					
} 

thirteen = data.frame(data2[data2$year == 13, ])
thirteen$rate = 0
for (a in 1:length(thirteen$New.Orders)){
  thirteen$rate[a] = thirteen$New.Orders[a]/ 3791.562					
} 

fourteen = data.frame(data2[data2$year == 14, ])
fourteen$rate = 0
for (a in 1:length(fourteen$New.Orders)){
  fourteen$rate[a] = fourteen$New.Orders[a]/ 4179.000					
} 

fif = data.frame(data2[data2$year == 15, ])
fif$rate = 0
for (a in 1:length(fif$New.Orders)){
  fif$rate[a] = fif$New.Orders[a]/ 4457.993					
} 

sixth = data.frame(data2[data2$year == 16, ])
sixth$rate = 0
for (a in 1:length(sixth$New.Orders)){
  sixth$rate[a] = sixth$New.Orders[a]/ 4449.278						
} 

sev = data.frame(data2[data2$year == 17, ])
sev$rate = 0
for (a in 1:length(sev$New.Orders)){
  sev$rate[a] = sev$New.Orders[a]/ 4418.833						
} 

ei = data.frame(data2[data2$year == 18, ])
ei$rate = 0
for (a in 1:length(ei$New.Orders)){
  ei$rate[a] = ei$New.Orders[a]/ 4641.597						
} 

ni = data.frame(data2[data2$year == 19, ])
ni$rate = 0
for (a in 1:length(ni$New.Orders)){
  ni$rate[a] = ni$New.Orders[a]/ 4545.285							
} 

tw = data.frame(data2[data2$year == 20, ])
tw$rate = 0
for (a in 1:length(tw$New.Orders)){
  tw$rate[a] = tw$New.Orders[a]/ 4507.417							
} 

twone = data.frame(data2[data2$year == 21, ])
twone$rate = 0
for (a in 1:length(twone$New.Orders)){
  twone$rate[a] = twone$New.Orders[a]/ 4389.403							
} 

twtw = data.frame(data2[data2$year == 22, ])
twtw$rate = 0
for (a in 1:length(twtw$New.Orders)){
  twtw$rate[a] = twtw$New.Orders[a]/ 4914.208								
} 

twth = data.frame(data2[data2$year == 23, ])
twth$rate = 0
for (a in 1:length(twth$New.Orders)){
  twth$rate[a] = twth$New.Orders[a]/ 5134.861								
} 

twfour = data.frame(data2[data2$year == 24, ])
twfour$rate = 0
for (a in 1:length(twfour$New.Orders)){
  twfour$rate[a] = twfour$New.Orders[a]/ 5238.583								
} 
```

```{r}
newbind = rbind(zero,one, three,four,five,six,seven,eight,nigh, ten, ele, thirteen, fourteen, fif, sixth,sev, ei, ni, tw, twone, twtw, twth,twfour)

#newbind = newbind%>%mutate(Date.new = make_date(year, month, day))

newbind = newbind%>%mutate(date = ymd(paste(year, month, day)))

newbind$date = as.Date(newbind$date, format =  "%m/%d/%Y")

```

```{r}
newbind = data.frame(newbind)

newdata = data.frame(subset(newbind, select = c(date, Total.Sales, rate)))

colnames(newdata) = c("Date", "SAAR.Total.Sales", "SAAR.New.Orders")

head(newdata)

# check number of data points of dataframe, use nrow(), check number of row of one variable using length()
nrow(newdata)
length(newdata$SAAR.Total.Sales)
length(newdata$SAAR.New.Orders)

new.sales.rate = ts(newdata$SAAR.Total.Sales, start = c(2000,1,1), frequency = 12)
new.orders.rate = ts(newdata$SAAR.New.Orders, start = c(2000,1,1), frequency = 12)

new.sales.rate.plot = autoplot(new.sales.rate) + xlab("Date") + ylab("Total Sales") + ggtitle("Total Sales - Seasonally Adjusted Annual Rate") 
new.sales.rate.plot

new.orders.rate.plot = autoplot(new.orders.rate) + xlab("Date") + ylab("New Orders") + ggtitle("New Orders - Seasonally Adjusted Annual Rate")
new.orders.rate.plot

ts_data = ts(newdata[,-1],start=2000,frequency=12)
autoplot(ts_data,main='SAAR of Total Sales  &  SAAR of New Orders',ylab="SAAR",xlab= 'Date')

```

```{r}
diff_ts = diff(ts_data)
head(diff_ts)
autoplot(diff_ts, main="1st-order Differenced SAAR of Total Sales and New Orders", ylab="1st-order Differenced SAAR", xlab="Date")
```

```{r}
ggAcf(diff_ts[, "SAAR.Total.Sales"], lag.max=200, col="brown1", main="Differenced SAAR of Total Sales")
```


```{r}
ggAcf(diff_ts[, "SAAR.New.Orders"], lag.max=200, col="darkturquoise", main="differenced SAAR of New Orders")
```

(1) From ACFs, I think it is now white noise since most lags are within 95% confidence band, some of the lags are outside the confidence band, due to the rest 5%.
(2) Code below I will start using 1st differenced data, since I think it is a white noise after differencing


```{r}
#new.sales.rate = ts(newdata$SAAR.Total.Sales, start = c(2000,1,1), frequency = 12)
#new.orders.rate = ts(newdata$SAAR.New.Orders, start = c(2000,1,1), frequency = 12)
#ts.merge = merge(xts(new.sales.rate, datte), xts(new.orders.rate, datte), join="inner")
colnames(diff_ts) = c( "New orders", "Total sales")
```


```{r}
# I applied VAR model to the entire time series with 1st order differenced. 
var.model.order = VARselect(diff_ts, lag.max = 20)
var.model.order$selection
```


```{r}
var.aic.model = VAR(diff_ts, p = 8)
summary(var.aic.model)
```



```{r}
var.bic.model = VAR(diff_ts, p = 1)
summary(var.bic.model)
```


```{r}
## checked residual with order 8 choosen by aic 
plot(ts(residuals(var.aic.model), start = 2000), main = "Residual Processes of VAR model (AIC)")
```



```{r}
## checked residual with order 8 choosen by bic 
plot(ts(residuals(var.bic.model), start = 2000), main = "Residual Processes of VAR model (BIC)")
```

Statistical test below is for aic order selection

```{r}
serial.test(var.aic.model)
```
P value is bigger than 0.05, fail to reject null of uncorrelated residuals


```{r}
arch.test(var.aic.model)
```

P value is close to 0, reject null of constant volatility


```{r}
normality.test(var.aic.model)
```

P value is close to 0, reject null of normality


Statistical test below is for bic order selection, the result is same as the one from aic. Also, no matter what choosen order is, the roots in within unit circle, so the var model appears to be stable. 


```{r}
serial.test(var.bic.model)
```


```{r}
arch.test(var.bic.model)
```


```{r}
normality.test(var.bic.model)
```


```{r}
granger_causality(var.aic.model)
```


```{r}
granger_causality(var.bic.model)
```

No matter model order chosed by aic or bic, since all p values are bigger than 0.05, there is no significant causal relationship between the variables. 



```{r}
VARselect(diff_ts,type = "both", lag.max = 10, exogen = diff_ts[, 1])$selection
```


## here I tried varx model on the new orders and total sales same time, but got a singular matrix, could not print out summary of the model. 

```{r}
# varx model on both time series.
varx.model = VAR(diff_ts, type = "both", p = 6, exogen = diff_ts[,1])
#summary(varx.model)
```

From the result, I think the value of order we can at most choose is 3. 


```{r}

```


```{r}

```


```{r}

```


```{r}

```


```{r}

```


```{r}

```


```{r}

```


```{r}

```


```{r}

```


```{r}

```


```{r}

```


```{r}

```


```{r}

```


```{r}

```


```{r}

```


```{r}










```

































































































































































































